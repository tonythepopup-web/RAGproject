import os
import re
import heapq
from itertools import product
from openpyxl import load_workbook
from collections import defaultdict
import numpy as np

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ í…ìŠ¤íŠ¸ ì •ì œ ë° ì •ë‹µ ë§¤ì¹­
def clean_text(text):
    """ë¬¸ìì—´ì—ì„œ ê´„í˜¸, ê³µë°±, íƒ­ ë“±ì„ ì œê±°í•©ë‹ˆë‹¤."""
    s = str(text or "")
    return re.sub(r"[()\u00A0 \t]", "", s).strip()

def is_valid_match(candidate, answer):
    """
    í›„ë³´ ë¬¸ì¥(candidate)ì´ ì •ë‹µ(answer)ì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    'ì˜' + í•œ ìë¦¬ ìˆ«ì í˜•íƒœì˜ ë§¤ì¹­ì€ ì œì™¸í•©ë‹ˆë‹¤.
    """
    pos = candidate.find(answer)
    if pos == -1:
        return False
    after = candidate[pos + len(answer):pos + len(answer) + 2]
    if after.startswith("ì˜") and len(after) >= 2 and after[1].isdigit():
        return False
    return True

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“¥ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜
def extract_candidate_rankings(filepath):
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ ê° ì§ˆë¬¸ë³„ Top-5 í›„ë³´ ë¬¸ì¥ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    2í–‰ë¶€í„° 5ê°œì”© ê±´ë„ˆë›°ë©° Eì—´ì˜ ê°’ì„ ì½ê³ , 
    DÂ·Eì—´ ëª¨ë‘ ë¹„ì–´ ìˆìœ¼ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    wb = load_workbook(filepath, data_only=True)
    ws = wb.worksheets[0]
    last_row = ws.max_row

    rankings = []
    for base_row in range(2, last_row + 1, 5):
        if ws.cell(row=base_row, column=4).value is None and ws.cell(row=base_row, column=5).value is None:
            break
        row = [clean_text(ws.cell(row=base_row + i, column=5).value) for i in range(5)]
        rankings.append(row)

    return rankings

def extract_ground_truths(filepath):
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ ê° ì§ˆë¬¸ë³„ ì •ë‹µ ë¬¸ì¥(Truth)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    2í–‰ë¶€í„° 5ê°œì”© ê±´ë„ˆë›°ë©° Dì—´ì˜ ê°’ì„ ì½ê³ , 
    Dì—´ì´ ë¹„ì–´ ìˆìœ¼ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    wb = load_workbook(filepath, data_only=True)
    ws = wb.worksheets[0]
    last_row = ws.max_row

    truths = []
    for base_row in range(2, last_row + 1, 5):
        if ws.cell(row=base_row, column=4).value is None:
            break
        gt = []
        for i in range(5):
            txt = clean_text(ws.cell(row=base_row + i, column=4).value)
            if txt:
                gt.append(txt)
        truths.append(gt)

    return truths

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Š í‰ê°€ í•¨ìˆ˜
def evaluate_top5_fraction_matched(predictions, ground_truths):
    """
    Top-5 ë‚´ì—ì„œ ì •ë‹µ í¬í•¨ ë¹„ìœ¨ì„ ì§ˆë¬¸ë³„ë¡œ ê³„ì‚°í•˜ê³  í•©ì‚°í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: (score_adjusted, raw_total_score)
    """
    total_score = 0.0
    valid_qs = 0

    for preds, golds in zip(predictions, ground_truths):
        if not golds:
            continue
        valid_qs += 1
        match_count = 0
        for g in golds:
            for p in preds[:5]:
                if is_valid_match(p, g):
                    match_count += 1
                    break
        total_score += match_count / len(golds)

    if valid_qs == 0:
        return 0.0, 0.0
    return total_score / valid_qs, total_score

def evaluate_global_fraction(predictions, ground_truths):
    """
    ì „ì²´ ì •ë‹µ ëŒ€ë¹„ ë§¤ì¹­ëœ ì •ë‹µ ìˆ˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: (fraction, matched_count, total_gold_count)
    """
    total_matched = 0
    total_gold = 0

    for preds, golds in zip(predictions, ground_truths):
        for g in golds:
            if any(is_valid_match(p, g) for p in preds[:5]):
                total_matched += 1
        total_gold += len(golds)

    if total_gold == 0:
        return 0.0, 0, 0
    total_matched -= 1  # ë³´ì •
    return total_matched / total_gold, total_matched, total_gold

def evaluate_soft(top2_list, ground_truths):
    """
    Soft Top-2 í‰ê°€ ë°©ì‹: ì •ë‹µì´ í•˜ë‚˜ë©´ 1ì , ë‘˜ ì´ìƒì´ë©´ match/2ë¡œ ê³„ì‚°,
    ì´ì ì€ ì§ˆë¬¸ ìˆ˜(100)ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    """
    total_score = 0
    for preds, golds in zip(top2_list, ground_truths):
        match = sum(1 for g in golds for p in preds if is_valid_match(p, g))
        if not golds:
            continue
        total_score += 1 if len(golds) == 1 else min(match / 2, 1.0)
    return total_score / 100, total_score


def evaluate_soft_global_top2(top2_list, ground_truths):
    total_matched = 0
    total_possible = 0
    for preds, golds in zip(top2_list, ground_truths):
        max_golds = min(len(golds), len(preds))
        total_possible += max_golds
        matched = sum(1 for p in preds[:2] if any(is_valid_match(p, g) for g in golds))
        total_matched += min(matched, max_golds)
    if total_possible == 0:
        return 0.0, 0, 0
    total_matched -= 1  # ë³´ì •
    return total_matched / total_possible, total_matched, total_possible



def evaluate_soft3(top3_list, ground_truths):
    """
    ì§ˆë¬¸ë³„ ì ìˆ˜ = (Top-3ë¡œ ë§ì¶˜ 'ì„œë¡œ ë‹¤ë¥¸' ì •ë‹µ ìˆ˜) / min(len(golds), 3)
    ë°˜í™˜: (ì§ˆë¬¸ í‰ê·  ì ìˆ˜, ì§ˆë¬¸ ì ìˆ˜ í•©, ìœ íš¨ ì§ˆë¬¸ ìˆ˜)
    """
    total_score = 0.0
    valid_qs = 0

    for preds, golds in zip(top3_list, ground_truths):
        if not golds:
            continue
        valid_qs += 1

        preds3 = preds[:3]
        matched_golds = set()
        for g in golds:
            if any(is_valid_match(p, g) for p in preds3):
                matched_golds.add(g)

        denom = min(len(golds), 3)
        total_score += (len(matched_golds) / denom) if denom > 0 else 0.0

    if valid_qs == 0:
        return 0.0, 0.0, 0
    return total_score / valid_qs, total_score

def evaluate_soft_global_top3(top3_list, ground_truths):
    total_matched = 0
    total_possible = 0
    for preds, golds in zip(top3_list, ground_truths):
        max_golds = min(len(golds), len(preds))
        total_possible += max_golds
        matched = sum(1 for p in preds[:3] if any(is_valid_match(p, g) for g in golds))
        total_matched += min(matched, max_golds)
    if total_possible == 0:
        return 0.0, 0, 0
    total_matched -= 1  # ë³´ì •
    return total_matched  / total_possible, total_matched, total_possible

def evaluate_soft4(top4_list, ground_truths):
    """
    ì§ˆë¬¸ë³„ ì ìˆ˜ = (Top-4ë¡œ ë§ì¶˜ 'ì„œë¡œ ë‹¤ë¥¸' ì •ë‹µ ìˆ˜) / min(len(golds), 4)
    ë°˜í™˜: (ì§ˆë¬¸ í‰ê·  ì ìˆ˜, ì§ˆë¬¸ ì ìˆ˜ í•©, ìœ íš¨ ì§ˆë¬¸ ìˆ˜)
    """
    total_score = 0.0
    valid_qs = 0

    for preds, golds in zip(top4_list, ground_truths):
        if not golds:
            continue
        valid_qs += 1

        preds4 = preds[:4]
        matched_golds = set()
        for g in golds:
            if any(is_valid_match(p, g) for p in preds4):
                matched_golds.add(g)

        denom = min(len(golds), 4)
        total_score += (len(matched_golds) / denom) if denom > 0 else 0.0

    if valid_qs == 0:
        return 0.0, 0.0, 0
    return total_score  / valid_qs, total_score


def evaluate_soft_global_top4(top4_list, ground_truths):
    total_matched = 0
    total_possible = 0
    for preds, golds in zip(top4_list, ground_truths):
        max_golds = min(len(golds), len(preds))
        total_possible += max_golds
        matched = sum(1 for p in preds[:4] if any(is_valid_match(p, g) for g in golds))
        total_matched += min(matched, max_golds)
    if total_possible == 0:
        return 0.0, 0, 0
    total_matched -= 1  # ë³´ì •
    return total_matched / total_possible, total_matched, total_possible

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¤– ì•™ìƒë¸” í•¨ìˆ˜
def weighted_ensemble_rankings_top5(models, weights):
    """ê°€ì¤‘ì¹˜ ì•™ìƒë¸”ë¡œ Top-5 í›„ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    ensemble_top5 = []
    for q in range(len(models[0])):
        score = defaultdict(float)
        for idx, model in enumerate(models):
            for rank, cand in enumerate(model[q]):
                if cand:
                    score[cand] += (5 - rank) * weights[idx]
        sorted_cands = sorted(score.items(), key=lambda x: -x[1])
        ensemble_top5.append([c for c, _ in sorted_cands[:5]])
    return ensemble_top5

def weighted_ensemble_rankings_top2(models, weights):
    """ê°€ì¤‘ì¹˜ ì•™ìƒë¸”ë¡œ Top-2 í›„ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    ensemble_top2 = []
    for q in range(len(models[0])):
        score = defaultdict(float)
        for idx, model in enumerate(models):
            for rank, cand in enumerate(model[q]):
                if cand:
                    score[cand] += (5 - rank) * weights[idx]
        sorted_cands = sorted(score.items(), key=lambda x: -x[1])
        ensemble_top2.append([c for c, _ in sorted_cands[:2]])
    return ensemble_top2

def run_weight_grid_search_v2_light(
    models,
    model_names,
    ground_truths,
    weight_range=(0.5, 1.5),
    step=0.25,
    normalize=True,
    top_n=5
):
    weight_candidates = np.arange(weight_range[0], weight_range[1] + step, step)
    combos = list(product(weight_candidates, repeat=len(models)))
    best_heap = []

    print(f"\nğŸ”¬ ì´ {len(combos):,}ê°œì˜ ê°€ì¤‘ì¹˜ ì¡°í•© ì‹¤í—˜ ì¤‘...")

    for weights in combos:
        if normalize:
            s = sum(weights)
            if s == 0:
                continue
            weights = [w / s for w in weights]

        ensemble_top2 = weighted_ensemble_rankings_top2(models, weights)
        frac2, matched2, possible2 = evaluate_soft_global_top2(ensemble_top2, ground_truths)
        heapq.heappush(best_heap, (frac2, matched2, possible2, list(weights)))
        
        if len(best_heap) > top_n:
            heapq.heappop(best_heap)

    best_heap.sort(reverse=True)
    print(f"\nâœ… ì•™ìƒë¸” ê·¸ë¦¬ë“œ íƒìƒ‰ Top-{top_n} ê²°ê³¼:")
    for i, result in enumerate(best_heap, 1):
        if len(result) == 4:
            frac, matched, total, weights = result
            print(f"\nğŸ¥‡ Rank {i} | ì •ë‹µí¬í•¨ë¥  = {frac:.4f} ({matched}/{total})")
        else:
            frac, matched, weights = result
            print(f"\nğŸ¥‡ Rank {i} | ì •í™•ë„ = {frac:.4f} ({matched:.1f}/100)")
        
        for name, w in zip(model_names, weights):
            print(f" - {name}: {w:.3f}")
    if len(best_heap[0]) == 4:
        return best_heap[0][3], best_heap[0][0]  # weights, score
    else:
        return best_heap[0][2], best_heap[0][0]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§ª ì‹¤í–‰ íŒŒíŠ¸
if __name__ == "__main__":
    from pathlib import Path
    SCRIPT_DIR = Path(__file__).resolve().parent
    model_folder = str(SCRIPT_DIR.parent.parent / "00_data" / "output" / "benchmark_result")
    model_weights_dict = {
        # "cosine_idf_0.7_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨": 1,
        # "cosine_idf_0.8_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨": 1,
        "cosine_idf_0.9_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨": 1,
        "ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨" : 1, 
        "keyword_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨" : 1,
        "rocchio feedback_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨" : 1,
        # "ì˜¤ì§Keyword_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨" : 1,
        # "í˜•íƒœì†Œë¶„ì„_0502_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨" : 1,
        "í˜•íƒœì†Œë¶„ì„_07005_ë²¤ì¹˜ë§ˆí¬v2_0711_ì „ì²˜ë¦¬ì™„ë£Œ_ë¼ìš°íŒ…í¬í•¨": 1

    }

    # ëª¨ë¸ íŒŒì¼ ë¡œë“œ
    model_files_all = sorted( 
        f for f in os.listdir(model_folder) if f.endswith(".xlsm")
    )
    model_files_all = [os.path.join(model_folder, f) for f in model_files_all]
    model_names_all = [os.path.splitext(os.path.basename(f))[0] for f in model_files_all]

    selected_files, selected_weights, selected_names = [], [], []
    print("ğŸ” ì‚¬ìš©ëœ ëª¨ë¸ ëª©ë¡:")
    for name, path in zip(model_names_all, model_files_all):
        if name in model_weights_dict:
            selected_files.append(path)
            selected_weights.append(model_weights_dict[name])
            selected_names.append(name)
            print(f" - {name} (w={model_weights_dict[name]:.2f})")

    print("\nğŸ“¥ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    ground_truths = extract_ground_truths(selected_files[0])
    model_rankings = [extract_candidate_rankings(f) for f in selected_files]
    all_model_rankings = [extract_candidate_rankings(f) for f in model_files_all]

   

    # 3ï¸âƒ£ ì „ì²´ ëª¨ë¸ Top-2 í‰ê°€
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-2 ì •ë‹µ í¬í•¨ë¥ :")
    for name, ranking in zip(model_names_all, all_model_rankings):
        top2_list = [r[:2] for r in ranking]
        acc2, score2 = evaluate_soft(top2_list, ground_truths)
        print(f"{name}: ì •í™•ë„ = {acc2:.3f} ({score2:.1f}/100)")

    # 4ï¸âƒ£ ì „ì²´ ëª¨ë¸ Top-2 Soft ì „ì—­ í‰ê°€
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-2 ì •ë‹µ í¬í•¨ë¥  (ì „ì—­ í‰ê°€):")
    for name, ranking in zip(model_names_all, all_model_rankings):
        top2_list = [r[:2] for r in ranking]
        soft_frac, soft_matched, soft_total = evaluate_soft_global_top2(top2_list, ground_truths)
        print(f"{name}: ì •ë‹µí¬í•¨ë¥  = {soft_frac:.3f} ({soft_matched}/{soft_total})")
        
        
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-3 ì •ë‹µ í¬í•¨ë¥ :")
    for name, ranking in zip(model_names_all, all_model_rankings):
        top3_list = [r[:3] for r in ranking]
        acc2, score2 = evaluate_soft3(top3_list, ground_truths)
        print(f"{name}: ì •í™•ë„ = {acc2:.3f} ({score2:.1f}/100)")

    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-3 ì •ë‹µ í¬í•¨ë¥  (ì „ì—­ í‰ê°€):")
    for name, ranking in zip(model_names_all, all_model_rankings):
        top3_list = [r[:3] for r in ranking]
        soft_frac, soft_matched, soft_total = evaluate_soft_global_top3(top3_list, ground_truths)
        print(f"{name}: ì •ë‹µí¬í•¨ë¥  = {soft_frac:.3f} ({soft_matched}/{soft_total})")
        
        
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-4 ì •ë‹µ í¬í•¨ë¥ :")
    for name, ranking in zip(model_names_all, all_model_rankings):
        top4_list = [r[:4] for r in ranking]
        acc2, score2 = evaluate_soft4(top4_list, ground_truths)
        print(f"{name}: ì •í™•ë„ = {acc2:.3f} ({score2:.1f}/100)")

    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top- ì •ë‹µ í¬í•¨ë¥  (ì „ì—­ í‰ê°€):")
    for name, ranking in zip(model_names_all, all_model_rankings):
        top4_list = [r[:4] for r in ranking]
        soft_frac, soft_matched, soft_total = evaluate_soft_global_top4(top4_list, ground_truths)
        print(f"{name}: ì •ë‹µí¬í•¨ë¥  = {soft_frac:.3f} ({soft_matched}/{soft_total})")
            
        
     # 1ï¸âƒ£ ì „ì²´ ëª¨ë¸ Top-5 í‰ê°€
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-5 ì •ë‹µ í¬í•¨ë¥ :")
    for name, ranking in zip(model_names_all, all_model_rankings):
        acc, score = evaluate_top5_fraction_matched(ranking, ground_truths)
        print(f"{name}: ì •í™•ë„ = {acc:.3f} ({score:.1f}/100)")

    # 2ï¸âƒ£ ì „ì²´ ëª¨ë¸ Top-5 ì „ì—­ í‰ê°€
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ Top-5 ì •ë‹µ í¬í•¨ë¥  (ì „ì—­ í‰ê°€):")
    for name, ranking in zip(model_names_all, all_model_rankings):
        acc, matched, total = evaluate_global_fraction(ranking, ground_truths)
        print(f"{name}: ì •ë‹µí¬í•¨ë¥  = {acc:.3f} ({matched}/{total})")

    # 5ï¸âƒ£ ì•™ìƒë¸” ê·¸ë¦¬ë“œ íƒìƒ‰ ì‹¤í–‰
    # run_weight_grid_search_v2_light(
    #     models=model_rankings,
    #     model_names=selected_names,
    #     ground_truths=ground_truths,
    #     weight_range=(0.5, 1.2),
    #     step=0.1,
    #     normalize=True,
    #     top_n=5,
    # )
